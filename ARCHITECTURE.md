# ğŸ—ï¸ System Architecture - Human Purchase Intent SSR

## Table of Contents

- [Overview](#overview)
- [High-Level Architecture](#high-level-architecture)
- [Data Flow](#data-flow)
- [Component Architecture](#component-architecture)
- [Mathematical Foundation](#mathematical-foundation)
- [System Components](#system-components)
- [API Architecture](#api-architecture)
- [Performance Architecture](#performance-architecture)
- [Deployment Architecture](#deployment-architecture)
- [Security Architecture](#security-architecture)

## Overview

The Human Purchase Intent system implements a **Semantic Similarity Rating (SSR)** methodology that converts textual consumer responses into probability distributions over a 1-5 Likert scale. The system achieves **90% of human test-retest reliability** through a sophisticated pipeline combining LLMs, embeddings, and statistical analysis.

### Core Design Principles

1. **Scientific Rigor**: Exact implementation of published research methodology
2. **Modularity**: Clean separation of concerns with well-defined interfaces
3. **Performance**: Vectorized operations and intelligent caching
4. **Scalability**: Async processing and horizontal scaling capability
5. **Reliability**: Comprehensive error handling and retry mechanisms

## High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              CLIENT LAYER                               â”‚
â”‚                    (Web UI, CLI, API Clients, SDKs)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ HTTPS/REST
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           API GATEWAY LAYER                            â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚   â”‚ Rate Limiter â”‚ Auth Handler â”‚ Load Balancerâ”‚ API Versioningâ”‚      â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       APPLICATION SERVICE LAYER                         â”‚
â”‚                         (FastAPI Application)                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚Survey Routesâ”‚Health/Metricsâ”‚Task Managerâ”‚WebSocket Handler      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        BUSINESS LOGIC LAYER                            â”‚
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                     SSR ORCHESTRATION ENGINE                    â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚    â”‚
â”‚  â”‚  â”‚   Text   â”‚â†’ â”‚Embedding â”‚â†’ â”‚Similarityâ”‚â†’ â”‚Distributionâ”‚      â”‚    â”‚
â”‚  â”‚  â”‚Elicitationâ”‚  â”‚Retrieval â”‚  â”‚   Calc   â”‚  â”‚Constructor â”‚      â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚   LLM Manager   â”‚  â”‚Demographics Mgr â”‚  â”‚ Evaluation Engineâ”‚      â”‚
â”‚  â”‚                 â”‚  â”‚                 â”‚  â”‚                 â”‚      â”‚
â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”â”‚  â”‚ â”Œâ”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”â”‚      â”‚
â”‚  â”‚ â”‚GPT-4â”‚ â”‚Geminiâ”‚â”‚  â”‚ â”‚Censusâ”‚ â”‚Biasâ”‚â”‚  â”‚ â”‚K^xyâ”‚ â”‚Ï calc â”‚â”‚      â”‚
â”‚  â”‚ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”˜â”‚  â”‚ â””â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”˜â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          DATA ACCESS LAYER                             â”‚
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚Reference Setsâ”‚  â”‚Embedding Cacheâ”‚  â”‚  PostgreSQL  â”‚               â”‚
â”‚  â”‚   (YAML)     â”‚  â”‚   (Pickle)    â”‚  â”‚   Database   â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚  Redis Queue â”‚  â”‚   S3 Storage  â”‚  â”‚ Prometheus DBâ”‚               â”‚
â”‚  â”‚   (Celery)   â”‚  â”‚   (Results)   â”‚  â”‚   (Metrics)  â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Data Flow

### Primary SSR Processing Pipeline

```
[User Input: Product Description + Demographics]
                    â”‚
                    â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  1. TEXT ELICITATION â”‚
        â”‚   (LLM Generation)   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â”‚ "I'd probably buy this product"
                    â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ 2. RESPONSE VALIDATIONâ”‚
        â”‚    (7-Check System)   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚ Valid Response
                    â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ 3. EMBEDDING RETRIEVALâ”‚
        â”‚  (OpenAI API + Cache) â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚ 1536-dim vector
                    â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚4. SIMILARITY CALCULATIONâ”‚
        â”‚  (Cosine to 30 refs)   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚ 5Ã—6 similarity matrix
                    â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚5. DISTRIBUTION CONSTRUCTIONâ”‚
        â”‚  (SSR Formula + Softmax)â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚ 6 distributions
                    â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ 6. MULTI-SET AVERAGINGâ”‚
        â”‚  (Mean across 6 sets) â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
    [Output: P(1), P(2), P(3), P(4), P(5)]
     Example: [0.05, 0.15, 0.30, 0.35, 0.15]
```

### Demographic Conditioning Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  US Census   â”‚â”€â”€â”€â”€â–¶â”‚  Stratified  â”‚â”€â”€â”€â”€â–¶â”‚ Demographic  â”‚
â”‚  2020 Data   â”‚     â”‚   Sampling   â”‚     â”‚   Cohort     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                                   â”‚
                                                   â–¼
                                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                         â”‚   Persona    â”‚
                                         â”‚ Conditioning â”‚
                                         â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   LLM Prompt:    â”‚
         â”‚ "You are a 28yo  â”‚     Ï = 50% â†’ 90.2%
         â”‚ Female, $50-75K, â”‚     (+40.2% improvement!)
         â”‚ San Francisco,   â”‚
         â”‚ Asian American"  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Component Architecture

### Core SSR Engine (`src/core/`)

```
SSREngine
    â”‚
    â”œâ”€â”€ SSRConfig                    # Configuration management
    â”‚   â”œâ”€â”€ temperature: float       # Distribution spread (0.5-1.5)
    â”‚   â”œâ”€â”€ offset: float            # Bias adjustment (default: 0)
    â”‚   â”œâ”€â”€ use_multi_set_averaging # Enable 6-set averaging
    â”‚   â””â”€â”€ reference_set_ids[]     # Which sets to use
    â”‚
    â”œâ”€â”€ Components
    â”‚   â”œâ”€â”€ EmbeddingRetriever      # OpenAI API integration
    â”‚   â”‚   â”œâ”€â”€ get_embedding()     # Single text â†’ vector
    â”‚   â”‚   â”œâ”€â”€ get_embeddings_batch() # Batch processing
    â”‚   â”‚   â””â”€â”€ PersistentCache     # SHA256-based cache
    â”‚   â”‚
    â”‚   â”œâ”€â”€ SimilarityCalculator    # Vectorized cosine similarity
    â”‚   â”‚   â”œâ”€â”€ calculate_similarities()
    â”‚   â”‚   â””â”€â”€ pre_normalize()     # Performance optimization
    â”‚   â”‚
    â”‚   â”œâ”€â”€ DistributionConstructor # SSR formula implementation
    â”‚   â”‚   â”œâ”€â”€ construct_distribution()
    â”‚   â”‚   â”œâ”€â”€ apply_temperature()
    â”‚   â”‚   â”œâ”€â”€ softmax_normalize()
    â”‚   â”‚   â””â”€â”€ average_across_sets()
    â”‚   â”‚
    â”‚   â””â”€â”€ ReferenceStatementManager # 6Ã—5 reference statements
    â”‚       â”œâ”€â”€ load_sets()
    â”‚       â”œâ”€â”€ compute_embeddings()
    â”‚       â””â”€â”€ validate_sets()
    â”‚
    â””â”€â”€ Methods
        â”œâ”€â”€ process_response()       # Single response â†’ distribution
        â”œâ”€â”€ process_responses_batch() # Batch processing
        â””â”€â”€ get_statistics()         # Performance metrics
```

### LLM Integration Layer (`src/llm/`)

```
LLMInterface (Abstract)
    â”‚
    â”œâ”€â”€ GPT4oInterface               # OpenAI implementation
    â”‚   â”œâ”€â”€ generate_response()     # Ï = 90.2%, K^xy = 0.88
    â”‚   â”œâ”€â”€ retry_logic()           # Exponential backoff
    â”‚   â””â”€â”€ token_tracking()        # Cost monitoring
    â”‚
    â”œâ”€â”€ GeminiInterface              # Google implementation
    â”‚   â”œâ”€â”€ generate_response()     # Ï = 90.6%, K^xy = 0.80
    â”‚   â””â”€â”€ temperature_control()   # T = 0.5, 1.0, 1.5
    â”‚
    â””â”€â”€ MockLLMInterface             # Testing without API

PromptManager
    â”‚
    â”œâ”€â”€ PromptTemplate               # Template structure
    â”‚   â”œâ”€â”€ system_prompt           # Role definition
    â”‚   â”œâ”€â”€ demographic_template    # Critical for +40% Ï
    â”‚   â”œâ”€â”€ product_template        # Product presentation
    â”‚   â””â”€â”€ response_format         # 1-3 sentences
    â”‚
    â””â”€â”€ Methods
        â”œâ”€â”€ format_prompt()          # Template â†’ prompt
        â””â”€â”€ validate_template()      # Quality checks

ResponseValidator
    â”‚
    â”œâ”€â”€ 7-Check Validation System
    â”‚   â”œâ”€â”€ length_check()          # 10-100 words
    â”‚   â”œâ”€â”€ sentence_count()        # 1-5 sentences
    â”‚   â”œâ”€â”€ meta_commentary()       # Detect "As an AI..."
    â”‚   â”œâ”€â”€ opinion_presence()      # Must express opinion
    â”‚   â”œâ”€â”€ product_relevance()     # On-topic check
    â”‚   â”œâ”€â”€ contradiction_check()   # Sentiment coherence
    â”‚   â””â”€â”€ language_quality()      # Grammar/completeness
    â”‚
    â””â”€â”€ confidence_scoring()         # 0.0-1.0 quality score
```

### Demographics System (`src/demographics/`)

```
DemographicProfile
    â”‚
    â”œâ”€â”€ Attributes
    â”‚   â”œâ”€â”€ age: int                # 18-120
    â”‚   â”œâ”€â”€ gender: str             # M/F/NB/Other
    â”‚   â”œâ”€â”€ income_level: str       # 6 brackets
    â”‚   â”œâ”€â”€ location: Location      # City, State, Country
    â”‚   â””â”€â”€ ethnicity: str          # US Census categories
    â”‚
    â””â”€â”€ Methods
        â”œâ”€â”€ to_dict()                # Serialization
        â””â”€â”€ validate()               # Range checks

DemographicSampler
    â”‚
    â”œâ”€â”€ US Census 2020 Data
    â”‚   â”œâ”€â”€ age_distribution        # Population pyramids
    â”‚   â”œâ”€â”€ income_brackets         # Economic stratification
    â”‚   â””â”€â”€ geographic_distribution # State populations
    â”‚
    â””â”€â”€ Sampling Strategies
        â”œâ”€â”€ stratified_sample()      # Proportional representation
        â”œâ”€â”€ quota_sample()           # Fixed quotas
        â””â”€â”€ custom_sample()          # User-defined

PersonaConditioner
    â”‚
    â”œâ”€â”€ conditioning_strength()     # Strong/Medium/Weak
    â”œâ”€â”€ format_persona()            # Profile â†’ prompt text
    â””â”€â”€ validate_conditioning()     # A/B testing framework

BiasDetector
    â”‚
    â”œâ”€â”€ detect_stereotypes()        # Pattern analysis
    â”œâ”€â”€ measure_homogenization()    # Within-group variance
    â””â”€â”€ mitigation_strategies()     # Prompt refinement
```

### Evaluation Framework (`src/evaluation/`)

```
MetricsCalculator
    â”‚
    â”œâ”€â”€ Distribution Metrics
    â”‚   â”œâ”€â”€ ks_similarity()         # K^xy = 1 - max|CDF_x - CDF_y|
    â”‚   â”œâ”€â”€ wasserstein_distance()  # Earth mover's distance
    â”‚   â””â”€â”€ jensen_shannon()        # JS divergence
    â”‚
    â”œâ”€â”€ Correlation Metrics
    â”‚   â”œâ”€â”€ pearson_correlation()   # Linear correlation
    â”‚   â”œâ”€â”€ spearman_correlation()  # Rank correlation
    â”‚   â””â”€â”€ correlation_attainment()# Ï = E[R^xy] / E[R^xx]
    â”‚
    â””â”€â”€ Error Metrics
        â”œâ”€â”€ mean_absolute_error()   # MAE < 0.5
        â”œâ”€â”€ root_mean_square()       # RMSE
        â””â”€â”€ max_error()              # Worst case

ReliabilitySimulator
    â”‚
    â”œâ”€â”€ test_retest_simulation()    # Split-half method
    â”œâ”€â”€ intra_class_correlation()   # ICC(2,1) model
    â””â”€â”€ human_baseline_comparison() # Ï_human = 1.0

BenchmarkComparator
    â”‚
    â”œâ”€â”€ load_human_data()           # 57 surveys, 9,300 responses
    â”œâ”€â”€ compare_distributions()     # Synthetic vs. human
    â””â”€â”€ generate_report()           # Performance metrics
```

## Mathematical Foundation

### Core SSR Formula

The system implements the following mathematical transformation:

```
SSR Distribution Formula:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
p_c,i(r) âˆ Î³(Ïƒ_r,i, t_c) - Î³(Ïƒ_â„“,i, t_c) + ÎµÂ·Î´_â„“,r
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Where:
- p_c,i(r) = Probability of rating r for concept c using reference set i
- Î³(Â·,Â·) = Cosine similarity function
- Ïƒ_r,i = Embedding of reference statement for rating r in set i
- t_c = Embedding of text response for concept c
- â„“ = Neutral reference (rating 3)
- Îµ = Offset parameter (default: 0)
- Î´_â„“,r = Kronecker delta (1 if â„“=r, 0 otherwise)

Temperature Scaling:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
scaled_score(r) = [Î³(Ïƒ_r, t_c) - Î³(Ïƒ_3, t_c)] / T

Softmax Normalization:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
p(r) = exp(scaled_score(r)) / Î£_k exp(scaled_score(k))

Multi-Set Averaging:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
P_final(r) = (1/N) Î£_i p_c,i(r)
```

### Performance Metrics

```
KS Similarity:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
K^xy = 1 - max_r |CDF_X(r) - CDF_Y(r)|
Target: K^xy â‰¥ 0.85

Correlation Attainment:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Ï = E[R^xy] / E[R^xx]
Where R^xy = test-retest correlation
Target: Ï â‰¥ 0.90

Mean Absolute Error:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
MAE = (1/M) Î£_c |mean_synthetic(c) - mean_human(c)|
Target: MAE < 0.5
```

## System Components

### 1. Text Elicitation Module

**Purpose**: Generate synthetic consumer responses using LLMs

**Implementation**:
```python
# src/llm/interfaces.py
class GPT4oInterface(LLMInterface):
    def generate_response(
        self,
        demographic_attributes: Dict,
        product_concept: ProductConcept,
        question_prompt: str,
        temperature: float = 1.0
    ) -> LLMResponse
```

**Key Features**:
- Demographic conditioning (+40% reliability improvement)
- Temperature control (0.5, 1.0, 1.5)
- Retry logic with exponential backoff
- Token usage tracking

### 2. Embedding Retrieval Module

**Purpose**: Convert text to 1536-dimensional vectors

**Implementation**:
```python
# src/core/embedding.py
class EmbeddingRetriever:
    def get_embedding(self, text: str) -> EmbeddingResult
    def get_embeddings_batch(self, texts: List[str]) -> List[EmbeddingResult]
```

**Key Features**:
- OpenAI text-embedding-3-small model
- Persistent SHA256-based caching
- Batch processing (up to 2048 texts)
- Cost: $0.02 per 1M tokens

### 3. Similarity Calculation Engine

**Purpose**: Compute cosine similarity between response and references

**Implementation**:
```python
# src/core/similarity.py
class SimilarityCalculator:
    def calculate_similarities(
        self,
        response_embedding: np.ndarray,
        reference_embeddings: np.ndarray,
        pre_normalized: bool = False
    ) -> SimilarityResult
```

**Key Features**:
- Vectorized NumPy operations
- Pre-normalization optimization
- Batch processing support
- Numerical stability checks

### 4. Distribution Constructor

**Purpose**: Transform similarities into probability distributions

**Implementation**:
```python
# src/core/distribution.py
class DistributionConstructor:
    def construct_distribution(
        self,
        similarities: SimilarityResult
    ) -> DistributionResult
```

**Key Features**:
- SSR formula implementation
- Temperature scaling
- Softmax with numerical stability
- Multi-set averaging

### 5. Reference Statement Manager

**Purpose**: Manage 6 sets of 5 reference statements each

**Implementation**:
```python
# src/core/reference_statements.py
class ReferenceStatementManager:
    def get_paper_default_sets(self) -> List[ReferenceStatementSet]
    def compute_all_embeddings(self, retriever: EmbeddingRetriever)
```

**Reference Sets** (from paper Table 5):
```
Set 1: Direct Likelihood
  1: "It's rather unlikely I'd buy it"
  2: "I probably wouldn't buy it"
  3: "I'm not sure if I'd buy it"
  4: "I'd probably buy it"
  5: "It's very likely I'd buy it"

[Sets 2-6 with alternative phrasings...]
```

## API Architecture

### RESTful Endpoints

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                API ENDPOINTS                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Health & Monitoring                              â”‚
â”‚   GET  /health                                   â”‚
â”‚   GET  /metrics                                  â”‚
â”‚                                                   â”‚
â”‚ Survey Management                                â”‚
â”‚   POST /api/v1/surveys                          â”‚
â”‚   GET  /api/v1/surveys/{id}                     â”‚
â”‚   POST /api/v1/surveys/{id}/execute             â”‚
â”‚   GET  /api/v1/surveys/{id}/status              â”‚
â”‚   GET  /api/v1/surveys/{id}/results             â”‚
â”‚                                                   â”‚
â”‚ SSR Processing                                   â”‚
â”‚   POST /api/v1/ssr/single                       â”‚
â”‚   POST /api/v1/ssr/batch                        â”‚
â”‚                                                   â”‚
â”‚ Demographics                                     â”‚
â”‚   POST /api/v1/demographics/cohort              â”‚
â”‚   GET  /api/v1/demographics/distributions       â”‚
â”‚                                                   â”‚
â”‚ Evaluation                                       â”‚
â”‚   POST /api/v1/evaluate/compare                 â”‚
â”‚   GET  /api/v1/evaluate/metrics                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Request/Response Flow

```
Client Request
     â”‚
     â–¼
[API Gateway]
     â”‚
     â”œâ”€â”€â–º Rate Limiting (60 req/min)
     â”œâ”€â”€â–º Authentication (API Key)
     â”œâ”€â”€â–º Request Validation (Pydantic)
     â”‚
     â–¼
[Route Handler]
     â”‚
     â”œâ”€â”€â–º Async Task Creation
     â”œâ”€â”€â–º Task ID Generation
     â”‚
     â–¼
[Background Worker]
     â”‚
     â”œâ”€â”€â–º SSR Processing
     â”œâ”€â”€â–º Progress Updates
     â”œâ”€â”€â–º Result Storage
     â”‚
     â–¼
[Response]
     â”‚
     â””â”€â”€â–º JSON Response
         {
           "task_id": "uuid",
           "status": "completed",
           "result": {
             "distribution": [0.05, 0.15, 0.30, 0.35, 0.15],
             "mean_rating": 3.4,
             "confidence": 0.92
           }
         }
```

## Performance Architecture

### Optimization Strategies

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           PERFORMANCE OPTIMIZATIONS              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                   â”‚
â”‚ 1. Vectorization                                 â”‚
â”‚    â””â”€â–º NumPy operations (100x speedup)          â”‚
â”‚                                                   â”‚
â”‚ 2. Caching                                       â”‚
â”‚    â”œâ”€â–º Embedding cache (60% hit rate)           â”‚
â”‚    â”œâ”€â–º Reference pre-computation                â”‚
â”‚    â””â”€â–º Redis result caching                     â”‚
â”‚                                                   â”‚
â”‚ 3. Batch Processing                              â”‚
â”‚    â”œâ”€â–º Embedding batches (2048 max)             â”‚
â”‚    â”œâ”€â–º LLM concurrent requests (20-30)          â”‚
â”‚    â””â”€â–º Database bulk operations                 â”‚
â”‚                                                   â”‚
â”‚ 4. Async Processing                              â”‚
â”‚    â”œâ”€â–º FastAPI async routes                     â”‚
â”‚    â”œâ”€â–º Celery task queue                        â”‚
â”‚    â””â”€â–º Concurrent survey execution              â”‚
â”‚                                                   â”‚
â”‚ 5. Resource Pooling                              â”‚
â”‚    â”œâ”€â–º Connection pooling (DB, Redis)           â”‚
â”‚    â”œâ”€â–º Thread pool executors                    â”‚
â”‚    â””â”€â–º Pre-allocated NumPy arrays               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Performance Metrics

```
Response Processing:
  Single: ~200ms (P95)
  Batch (100): ~5 seconds

API Throughput:
  Requests: 100+ req/sec
  Surveys: 10+ concurrent

Resource Usage:
  Memory: ~500MB baseline
  CPU: 2-4 cores recommended
  Disk: 1GB for cache

Scalability:
  Horizontal: Stateless design
  Vertical: Memory-bound operations
  Queue: Celery workers scale independently
```

## Deployment Architecture

### Production Deployment

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              LOAD BALANCER                       â”‚
â”‚                (nginx/ALB)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                     â”‚
         â–¼                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   API Server 1  â”‚   â”‚   API Server 2  â”‚
â”‚   (FastAPI)     â”‚   â”‚   (FastAPI)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                     â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                     â”‚
         â–¼                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Celery Worker 1â”‚   â”‚  Celery Worker 2â”‚
â”‚  (SSR Processing)â”‚   â”‚  (SSR Processing)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                     â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                               â”‚
    â–¼                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚PostgreSQLâ”‚                â”‚  Redis   â”‚
â”‚(Primary) â”‚                â”‚ (Cache)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Container Architecture

```yaml
# docker-compose.yml
services:
  api:
    build: .
    ports: ["8000:8000"]
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    depends_on:
      - postgres
      - redis

  worker:
    build: .
    command: celery worker
    depends_on:
      - redis

  postgres:
    image: postgres:15
    volumes:
      - postgres_data:/var/lib/postgresql/data

  redis:
    image: redis:7
    volumes:
      - redis_data:/data
```

### Kubernetes Architecture

```yaml
# k8s-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ssr-api
spec:
  replicas: 3
  template:
    spec:
      containers:
      - name: api
        image: ssr-system:latest
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "1Gi"
            cpu: "1000m"
```

## Security Architecture

### Security Layers

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              SECURITY ARCHITECTURE               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                   â”‚
â”‚ 1. Network Security                              â”‚
â”‚    â”œâ”€â–º HTTPS/TLS 1.3                            â”‚
â”‚    â”œâ”€â–º API Gateway firewall                     â”‚
â”‚    â””â”€â–º VPC isolation                            â”‚
â”‚                                                   â”‚
â”‚ 2. Authentication & Authorization                â”‚
â”‚    â”œâ”€â–º API key authentication                   â”‚
â”‚    â”œâ”€â–º JWT for sessions                         â”‚
â”‚    â””â”€â–º Role-based access control                â”‚
â”‚                                                   â”‚
â”‚ 3. Rate Limiting                                 â”‚
â”‚    â”œâ”€â–º Per-user quotas                          â”‚
â”‚    â”œâ”€â–º IP-based throttling                      â”‚
â”‚    â””â”€â–º DDoS protection                          â”‚
â”‚                                                   â”‚
â”‚ 4. Data Protection                               â”‚
â”‚    â”œâ”€â–º Encryption at rest (AES-256)             â”‚
â”‚    â”œâ”€â–º Encryption in transit (TLS)              â”‚
â”‚    â””â”€â–º PII anonymization                        â”‚
â”‚                                                   â”‚
â”‚ 5. API Security                                  â”‚
â”‚    â”œâ”€â–º Input validation                         â”‚
â”‚    â”œâ”€â–º SQL injection prevention                 â”‚
â”‚    â””â”€â–º XSS protection                           â”‚
â”‚                                                   â”‚
â”‚ 6. Monitoring & Audit                            â”‚
â”‚    â”œâ”€â–º Security event logging                   â”‚
â”‚    â”œâ”€â–º Anomaly detection                        â”‚
â”‚    â””â”€â–º Compliance tracking                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Security Best Practices

1. **API Keys**: Never commit to version control
2. **Secrets Management**: Use environment variables or secret managers
3. **Input Validation**: Pydantic models for all inputs
4. **Error Handling**: Never expose internal errors to clients
5. **Logging**: Sanitize logs of PII and secrets
6. **Dependencies**: Regular security updates and audits

## Monitoring & Observability

### Metrics Collection

```
Prometheus Metrics
    â”‚
    â”œâ”€â”€ System Metrics
    â”‚   â”œâ”€â”€ CPU usage
    â”‚   â”œâ”€â”€ Memory usage
    â”‚   â”œâ”€â”€ Disk I/O
    â”‚   â””â”€â”€ Network traffic
    â”‚
    â”œâ”€â”€ Application Metrics
    â”‚   â”œâ”€â”€ Request rate
    â”‚   â”œâ”€â”€ Response time
    â”‚   â”œâ”€â”€ Error rate
    â”‚   â””â”€â”€ Queue depth
    â”‚
    â”œâ”€â”€ Business Metrics
    â”‚   â”œâ”€â”€ Surveys processed
    â”‚   â”œâ”€â”€ Responses generated
    â”‚   â”œâ”€â”€ API calls made
    â”‚   â””â”€â”€ Cache hit rate
    â”‚
    â””â”€â”€ Custom Metrics
        â”œâ”€â”€ SSR accuracy (K^xy)
        â”œâ”€â”€ Reliability (Ï)
        â””â”€â”€ Cost per response
```

### Logging Architecture

```
Application Logs
    â”‚
    â”œâ”€â”€ Structured JSON
    â”‚   {
    â”‚     "timestamp": "2024-01-01T12:00:00Z",
    â”‚     "level": "INFO",
    â”‚     "service": "ssr-engine",
    â”‚     "message": "Processing response",
    â”‚     "context": {
    â”‚       "survey_id": "uuid",
    â”‚       "response_count": 150,
    â”‚       "processing_time_ms": 234
    â”‚     }
    â”‚   }
    â”‚
    â””â”€â”€ Log Aggregation
        â”œâ”€â”€ ElasticSearch
        â”œâ”€â”€ CloudWatch
        â””â”€â”€ Datadog
```

## Development Workflow

### CI/CD Pipeline

```
Developer Push
     â”‚
     â–¼
[GitHub Actions]
     â”‚
     â”œâ”€â”€â–º Linting (ruff, black)
     â”œâ”€â”€â–º Type Checking (mypy)
     â”œâ”€â”€â–º Unit Tests (pytest)
     â”œâ”€â”€â–º Integration Tests
     â”œâ”€â”€â–º Security Scan
     â”‚
     â–¼
[Build & Package]
     â”‚
     â”œâ”€â”€â–º Docker Build
     â”œâ”€â”€â–º Push to Registry
     â”‚
     â–¼
[Deploy to Staging]
     â”‚
     â”œâ”€â”€â–º Smoke Tests
     â”œâ”€â”€â–º Performance Tests
     â”‚
     â–¼
[Deploy to Production]
     â”‚
     â””â”€â”€â–º Blue-Green Deployment
```

## Conclusion

The Human Purchase Intent SSR system represents a sophisticated implementation of cutting-edge research in synthetic consumer behavior modeling. The architecture prioritizes:

1. **Scientific Accuracy**: Faithful implementation of published methodology
2. **Performance**: Optimized for high-throughput processing
3. **Scalability**: Horizontal scaling through stateless design
4. **Reliability**: Comprehensive error handling and retry mechanisms
5. **Security**: Multi-layer security architecture
6. **Observability**: Detailed monitoring and logging

The modular design allows for easy extension and modification while maintaining the core SSR methodology that achieves 90% of human test-retest reliability.

---

*For implementation details, see the source code in `src/`. For usage examples, see `README.md`. For research background, see `Human_Purchase_Intent.pdf`.*